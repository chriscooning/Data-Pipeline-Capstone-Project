{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "from collections import namedtuple, Counter\n",
    "from sklearn.cluster import KMeans\n",
    "# from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.sql.functions import col, pandas_udf, udf, struct, PandasUDFType, split\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"pyarrow==0.14.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.expanduser(\"~/.aws/credentials\"))\n",
    "access_id = config.get('fohr_derrick', \"aws_access_key_id\") \n",
    "access_key = config.get('fohr_derrick', \"aws_secret_access_key\")\n",
    "hadoop_conf=spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3native.NativeS3FileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.awsAccessKeyId\", access_id)\n",
    "hadoop_conf.set(\"fs.s3a.awsSecretAccessKey\", access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Databricks ImageIO source code:\n",
    "_OcvType = namedtuple(\"OcvType\", [\"name\", \"ord\", \"nChannels\", \"dtype\"])\n",
    "\n",
    "_SUPPORTED_OCV_TYPES = (\n",
    "    _OcvType(name=\"CV_8UC1\", ord=0, nChannels=1, dtype=\"uint8\"),\n",
    "    _OcvType(name=\"CV_32FC1\", ord=5, nChannels=1, dtype=\"float32\"),\n",
    "    _OcvType(name=\"CV_8UC3\", ord=16, nChannels=3, dtype=\"uint8\"),\n",
    "    _OcvType(name=\"CV_32FC3\", ord=21, nChannels=3, dtype=\"float32\"),\n",
    "    _OcvType(name=\"CV_8UC4\", ord=24, nChannels=4, dtype=\"uint8\"),\n",
    "    _OcvType(name=\"CV_32FC4\", ord=29, nChannels=4, dtype=\"float32\"),\n",
    ")\n",
    "\n",
    "#  NOTE: likely to be migrated to Spark ImageSchema code in the near future.\n",
    "_OCV_TYPES_BY_ORDINAL = {m.ord: m for m in _SUPPORTED_OCV_TYPES}\n",
    "\n",
    "\n",
    "def imageTypeByOrdinal(ordinal):\n",
    "    if not ordinal in _OCV_TYPES_BY_ORDINAL:\n",
    "        raise KeyError(\"unsupported image type with ordinal %d, supported OpenCV types = %s\" % (\n",
    "            ordinal, str(_SUPPORTED_OCV_TYPES)))\n",
    "    return _OCV_TYPES_BY_ORDINAL[ordinal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 's3a://social-system-test/instagram_graph_image_store/1/*/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"image\").option(\"dropInvalid\", True).load(IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"6400\") # Set a large batch size in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = df.select('image.origin',\n",
    "                        'image.height',\n",
    "                        'image.width',\n",
    "                        'image.mode',\n",
    "                        'image.nChannels',\n",
    "                        'image.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = image_batch.withColumn('igId', split('origin', \"/\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_many_classify(image, shape):\n",
    "\n",
    "    # cluster and assign labels to the pixels\n",
    "    clt = KMeans(n_clusters=6, n_init=20, precompute_distances=True).fit(image)\n",
    "\n",
    "    # clt = KMeans(n_clusters = k).fit(image) <-- slower method with more steps in finding true cluster centers\n",
    "    labels = clt.predict(image)\n",
    "\n",
    "#     # count labels to find most popular\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    # subset out most popular centroid\n",
    "    dom_color_1 = clt.cluster_centers_[label_counts.most_common(1)[0][0]]\n",
    "    dom_color_2 = clt.cluster_centers_[label_counts.most_common(2)[1][0]]\n",
    "    dom_color_3 = clt.cluster_centers_[label_counts.most_common(3)[2][0]]\n",
    "    dom_color_4 = clt.cluster_centers_[label_counts.most_common(4)[3][0]]\n",
    "    dom_color_5 = clt.cluster_centers_[label_counts.most_common(5)[4][0]]\n",
    "    dom_color_6 = clt.cluster_centers_[label_counts.most_common(6)[5][0]]\n",
    "\n",
    "    # create a square showing dominant color of equal size to input image for testing\n",
    "    dom_color_1_hsv = np.full(shape, dom_color_1, dtype='uint8')\n",
    "    # convert to bgr color space for display in testing\n",
    "    dom_color_1_rgb = cv2.cvtColor(dom_color_1_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    dom_color_2_hsv = np.full(shape, dom_color_2, dtype='uint8')\n",
    "    dom_color_2_rgb = cv2.cvtColor(dom_color_2_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    dom_color_3_hsv = np.full(shape, dom_color_3, dtype='uint8')\n",
    "    dom_color_3_rgb = cv2.cvtColor(dom_color_3_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    dom_color_4_hsv = np.full(shape, dom_color_4, dtype='uint8')\n",
    "    dom_color_4_rgb = cv2.cvtColor(dom_color_4_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    dom_color_5_hsv = np.full(shape, dom_color_5, dtype='uint8')\n",
    "    dom_color_5_rgb = cv2.cvtColor(dom_color_5_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    dom_color_6_hsv = np.full(shape, dom_color_6, dtype='uint8')\n",
    "    dom_color_6_rgb = cv2.cvtColor(dom_color_6_hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    # concat input image and dom color square side by side for display\n",
    "    #output_image = np.hstack((bgr_image[:,:,::-1], dom_color_1_rgb, dom_color_2_rgb, dom_color_3_rgb))\n",
    "\n",
    "    hex1 = '#%02x%02x%02x' % (\n",
    "        dom_color_1_rgb[0][0][0], dom_color_1_rgb[0][0][1], dom_color_1_rgb[0][0][2])\n",
    "    hex2 = '#%02x%02x%02x' % (\n",
    "        dom_color_2_rgb[0][0][0], dom_color_2_rgb[0][0][1], dom_color_2_rgb[0][0][2])\n",
    "    hex3 = '#%02x%02x%02x' % (\n",
    "        dom_color_3_rgb[0][0][0], dom_color_3_rgb[0][0][1], dom_color_3_rgb[0][0][2])\n",
    "    hex4 = '#%02x%02x%02x' % (\n",
    "        dom_color_4_rgb[0][0][0], dom_color_4_rgb[0][0][1], dom_color_4_rgb[0][0][2])\n",
    "    hex5 = '#%02x%02x%02x' % (\n",
    "        dom_color_5_rgb[0][0][0], dom_color_5_rgb[0][0][1], dom_color_5_rgb[0][0][2])\n",
    "    hex6 = '#%02x%02x%02x' % (\n",
    "        dom_color_6_rgb[0][0][0], dom_color_6_rgb[0][0][1], dom_color_6_rgb[0][0][2])\n",
    "\n",
    "    # return list of dict\n",
    "    color_list = [\n",
    "        {'percentage': (label_counts.most_common(6)[0][1]/image.shape[0]),\n",
    "            'red': int(dom_color_1_rgb[0][0][0]),\n",
    "            'green': int(dom_color_1_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_1_rgb[0][0][2]),\n",
    "            'hex': hex1\n",
    "        },\n",
    "        {\n",
    "            'percentage': (label_counts.most_common(2)[1][1]/image.shape[0]),\n",
    "            'red': int(dom_color_2_rgb[0][0][0]),\n",
    "            'green': int(dom_color_2_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_2_rgb[0][0][2]),\n",
    "            'hex': hex2\n",
    "        },\n",
    "        {\n",
    "            'percentage': (label_counts.most_common(3)[2][1]/image.shape[0]),\n",
    "            'red': int(dom_color_3_rgb[0][0][0]),\n",
    "            'green': int(dom_color_3_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_3_rgb[0][0][2]),\n",
    "            'hex': hex3\n",
    "        },\n",
    "        {\n",
    "            'percentage': (label_counts.most_common(4)[3][1]/image.shape[0]),\n",
    "            'red': int(dom_color_4_rgb[0][0][0]),\n",
    "            'green': int(dom_color_4_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_4_rgb[0][0][2]),\n",
    "            'hex': hex4\n",
    "        },\n",
    "        {\n",
    "            'percentage': (label_counts.most_common(5)[4][1]/image.shape[0]),\n",
    "            'red': int(dom_color_5_rgb[0][0][0]),\n",
    "            'green': int(dom_color_5_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_5_rgb[0][0][2]),\n",
    "            'hex': hex5\n",
    "        },\n",
    "        {\n",
    "            'percentage': (label_counts.most_common(6)[5][1]/image.shape[0]),\n",
    "            'red': int(dom_color_6_rgb[0][0][0]),\n",
    "            'green': int(dom_color_6_rgb[0][0][1]),\n",
    "            'blue': int(dom_color_6_rgb[0][0][2]),\n",
    "            'hex': hex6\n",
    "        }\n",
    "    ]\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    StructField('igId', StringType(), True),\n",
    "    StructField('colors', StringType(), True)\n",
    "]\n",
    "\n",
    "@pandas_udf(StructType(attributes), PandasUDFType.GROUPED_MAP)\n",
    "def convert_imageStruct(key, pdf):\n",
    "    bgr_image = []\n",
    "    for index, row in pdf.iterrows():\n",
    "        shape = (row['height'], \n",
    "                 row['width'],\n",
    "                 row['nChannels'])\n",
    "        dtype = imageTypeByOrdinal(row['mode']).dtype\n",
    "        image = np.ndarray(shape, dtype, row[5])\n",
    "        image = image[..., ::-1]\n",
    "        image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "        if len(bgr_image) == 0:\n",
    "            bgr_image=image\n",
    "        else:\n",
    "            bgr_image = np.concatenate((bgr_image, image), axis=0)\n",
    "    shape = bgr_image.shape\n",
    "    # convert to HSV; this is a better representation of how we see color\n",
    "    hsv_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
    "    image = hsv_image.reshape((hsv_image.shape[0] * hsv_image.shape[1], 3))\n",
    "    colors = color_many_classify(image, shape)\n",
    "    return pd.DataFrame([[key[0], str(colors)]], columns=['igId', 'colors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "udf to apply convert_image_struct\n",
    "\n",
    "break up origin string\n",
    "\n",
    "group by user id\n",
    "\n",
    "concate image values \n",
    "\n",
    "udf to map colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = image_batch.groupby('igId').apply(convert_imageStruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derricklewis/anaconda3/envs/pipeline/lib/python3.7/site-packages/pyarrow/__init__.py:157: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n",
      "  warnings.warn(\"pyarrow.open_stream is deprecated, please use \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>igId</th>\n",
       "      <th>colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'percentage': 0.5563760683760683, 'red': 235...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  igId                                             colors\n",
       "0    1  [{'percentage': 0.5563760683760683, 'red': 235..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.write.mode(\"overwrite\").save(\"/color_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_batch_udf = pandas_udf(ArrayType(FloatType()), PandasUDFType.SCALAR)(predict_batch)\n",
    "#predictions = df.select(predict_batch_udf(col(\"image.data\")).alias(\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.write.mode(\"overwrite\").save(\"/tmp/predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could solve color classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batc2h=image_batch.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_convert_imageStruct(pdf):\n",
    "    group_key = pdf[group_column].iloc[0]\n",
    "    bgr_image = []\n",
    "    for index, row in pdf.iterrows():\n",
    "        shape = (row['height'], \n",
    "                 row['width'],\n",
    "                 row['nChannels'])\n",
    "        dtype = imageTypeByOrdinal(row['mode']).dtype\n",
    "        image = np.ndarray(shape, dtype, row[5])\n",
    "        image = image[..., ::-1]\n",
    "        image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "        if len(bgr_image) == 0:\n",
    "            bgr_image=image\n",
    "        else:\n",
    "            bgr_image = np.concatenate((bgr_image, image), axis=0)\n",
    "\n",
    "    # convert to HSV; this is a better representation of how we see color\n",
    "    print(bgr_image.shape)\n",
    "    hsv_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
    "    image = hsv_image.reshape((hsv_image.shape[0] * hsv_image.shape[1], 3))\n",
    "    print(image.shape[0])\n",
    "    return pd.DataFrame([[group_key, list(image)]], columns=['id', 'newImage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = new_convert_imageStruct(image_batc2h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('pipeline': conda)",
   "language": "python",
   "name": "python38264bitpipelineconda12941fbee1d84e2291001de63dfa62f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
